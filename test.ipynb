{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbff7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from monai.transforms import (\n",
    "    Compose, NormalizeIntensityd, AsDiscreted, LoadImaged, EnsureChannelFirstd,ConcatItemsd,DeleteItemsd,\n",
    "    Resized, Rand3DElasticd, RandFlipd, RandRotate90d, Rand3DElasticd,RandBiasFieldd,SpatialPadd,\n",
    "    RandShiftIntensityd, EnsureTyped, Activationsd, EnsureTyped, KeepLargestConnectedComponentd\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42440de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'E:\\\\Codigos\\\\Python\\\\Brain Stroke Segmentation\\\\ISLE2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ced8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwi_dir = Path(dataset_path)/'DWIs'\n",
    "flair_dir = Path(dataset_path)/'FLAIRs'\n",
    "label_dir = Path(dataset_path)/'Labels'\n",
    "        \n",
    "# Get sorted lists of NIfTI files using pathlib\n",
    "dwis = sorted(dwi_dir.glob('*.nii.gz'))\n",
    "labels = sorted(label_dir.glob('*.nii.gz'))\n",
    "flairs = sorted(flair_dir.glob('*.nii.gz'))\n",
    "        \n",
    "       \n",
    "# Create dictionary list with string paths\n",
    "datalist = [ {'dwi': str(dwi), 'flair': str(flair),'label': str(lbl)} for dwi,flair, lbl in zip(dwis,flairs, labels)]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812c5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_transforms = Compose([\n",
    "    LoadImaged(keys=[\"dwi\",\"flair\" ,\"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"dwi\",\"flair\", \"label\"]),\n",
    "    Resized(keys=[\"dwi\",'flair' ,\"label\"],spatial_size=(176,176,64),mode=(\"trilinear\",\"trilinear\", \"nearest\")),\n",
    "    NormalizeIntensityd(keys=[\"dwi\",\"flair\"], nonzero=True, channel_wise=True),\n",
    "    ConcatItemsd(keys=[\"dwi\",\"flair\"], name = \"image\",dim = 0),\n",
    "    DeleteItemsd(keys=[\"dwi\",\"flair\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f111f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.5\n",
    "rand_transforms = Compose([\n",
    "    #RandSpatialCropd(keys=[\"image\", \"label\"],roi_size=(176,176,64),random_size=False),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=prob, spatial_axis=0),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=prob, spatial_axis=1),\n",
    "    RandFlipd(keys=[\"image\", \"label\"], prob=prob, spatial_axis=2),\n",
    "    RandRotate90d(keys=[\"image\", \"label\"],max_k=3, prob=prob),\n",
    "    #Rand3DElasticd(keys=[\"image\", \"label\"], sigma_range=(5,7),magnitude_range=(50,100),padding_mode='zeros',prob=0.2, mode=(\"trilinear\",\"nearest\")),\n",
    "    RandBiasFieldd(keys=[\"image\"],coeff_range=(0.1,0.2),prob=prob),\n",
    "    RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=prob)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789e0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessing = Compose([det_transforms,rand_transforms])\n",
    "val_preprocessing = Compose([det_transforms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa05c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 176, 176, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_preprocessing(datalist[20])\n",
    "X['image'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35486673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(\n",
    "            data=datalist[0:200],\n",
    "            transform=train_preprocessing,\n",
    "        )\n",
    "val_ds = Dataset(\n",
    "            data=datalist[201:249],\n",
    "            transform=val_preprocessing, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbed94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'E:\\\\Codigos\\\\Python\\\\Brain Stroke Segmentation\\\\pretrained_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f7a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet, SegResNet # Changed to UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520e8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegResNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=2,\n",
    "            out_channels=1,\n",
    "            init_filters=16,\n",
    "            blocks_down=(1, 2, 2, 4),\n",
    "            blocks_up=(1, 1, 1),\n",
    "            dropout_prob=0.2\n",
    "        ).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c3c35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = torch.load(pretrained_path, map_location='cpu')\n",
    "model_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e4b439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 3, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_dict['convInit.conv.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "969f50a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 3, 3, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['convInit.conv.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e87723ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle input channel mismatch\n",
    "#if 'convInit.conv.weight' in pretrained_dict:\n",
    "# Pretrained has 4 input channels, we have 2\n",
    "init_weights = pretrained_dict['convInit.conv.weight']\n",
    "out_weights = pretrained_dict['conv_final.2.conv.weight'] \n",
    "out_bias = pretrained_dict['conv_final.2.conv.bias']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f46f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_init_weights = torch.cat((init_weights.mean(dim=1, keepdim=True), init_weights.mean(dim=1, keepdim=True)), dim=1) \n",
    "adapted_out_weights = out_weights.mean(dim=0, keepdim=True)\n",
    "adapted_out_bias = out_bias.mean(dim=0, keepdim=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea9e333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Use just the first channel (if you know it's most relevant)\n",
    "# adapted_weights = pretrained_weights[:, :1, :, :, :].clone()\n",
    "pretrained_dict['convInit.conv.weight'] = adapted_init_weights\n",
    "pretrained_dict['conv_final.2.conv.weight'] = adapted_out_weights\n",
    "pretrained_dict['conv_final.2.conv.bias'] = adapted_out_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c238ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filter out unnecessary keys (mismatched layers)\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.shape == model_dict[k].shape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c48738a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.update(pretrained_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2909aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict, strict=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
